\section{Evaluation}
\label{sec:evaluation}

In this section, we present a comprehensive evaluation of the proposed RTXGNN framework. We assess its performance against state-of-the-art baselines, analyze its robustness and efficiency, and validate its interpretability using three distinct datasets: one financial transaction network, one review fraud network, and one synthetic network with controlled fraud patterns.

\subsection{Experimental Setup}

\subsubsection{Datasets}
We utilize three datasets to evaluate our model:
\begin{enumerate}
    \item \textbf{Elliptic Bitcoin Dataset}: A real-world transaction graph consisting of 203,769 nodes and 234,355 edges. Nodes represent transactions, and edges represent payment flows. The dataset is temporally split into 49 time steps. We use steps 1-30 for training, 31-34 for validation, and 35-49 for testing.
    \item \textbf{YelpChi Dataset}: A real-world fraud detection dataset containing 45,954 reviews (nodes) and 3,846,979 edges representing social relations. Reviews are labeled as spam (fraud) or legitimate. This dataset tests the model's ability to generalize to a different domain (e-commerce/reviews) with different structural properties.
    \item \textbf{Synthetic Money Laundering Network}: To rigorously test the model's ability to detect specific structural fraud patterns, we generated a synthetic graph with 5,000 nodes. This dataset injects specific "fraud ring" typologies (cyclic transaction patterns) into a scale-free base network, allowing us to verify if the model can identify and explain these known structures.
\end{enumerate}

\subsubsection{Baselines}
We compare RTXGNN with the following baseline models:
\begin{itemize}
    \item \textbf{GCN}: Graph Convolutional Network.
    \item \textbf{GAT}: Graph Attention Network.
    \item \textbf{GraphSAGE}: Inductive representation learning on large graphs.
    \item \textbf{MLP}: Multi-Layer Perceptron (node features only).
\end{itemize}

\subsection{Performance Analysis on Elliptic Dataset}

\subsubsection{Overall Classification Performance}
Table 1 presents the classification performance of RTXGNN compared to the baselines on the Elliptic dataset. RTXGNN achieves the highest F1-score, demonstrating that its combination of temporal encoding and self-explainable aggregation effectively captures the complex dynamics of illicit transactions.

\begin{table}[h]
    \centering
    \caption{Comparative Performance on Elliptic Dataset}
    \begin{tabular}{lcccc}
        \hline
        \textbf{Model} & \textbf{F1-Score} & \textbf{AUC} & \textbf{Precision} & \textbf{Recall} \\
        \hline
        \textbf{RTXGNN (Ours)} & \textbf{0.5125} & \textbf{0.8662} & - & - \\
        GAT & 0.4285 & 0.8659 & - & - \\
        GraphSAGE & 0.4141 & 0.8735 & - & - \\
        GCN & 0.2697 & 0.8217 & - & - \\
        MLP & 0.4538 & 0.8638 & - & - \\
        \hline
    \end{tabular}
    \label{tab:performance}
\end{table}

Figure~\ref{fig:learning_curves} illustrates the training stability of RTXGNN. The model converges steadily, with the test F1-score improving consistently over epochs.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Figures/learning_curves.png}
    \caption{Learning curves showing Training Loss and Test F1-Score over epochs.}
    \label{fig:learning_curves}
\end{figure}

\subsection{Advanced Robustness and Efficiency Analysis}

\subsubsection{Label Efficiency}
We evaluated the model's performance when trained on limited labeled data. As shown in Table 2, RTXGNN maintains robust performance even with only 10\% of the training data, significantly outperforming the MLP baseline which degrades rapidly in low-data regimes.

\subsubsection{Temporal Stability}
Financial fraud patterns evolve over time (concept drift). Figure~\ref{fig:temporal_stability} plots the F1-score of RTXGNN across the unseen test time steps (35-49). The model exhibits superior stability compared to static baselines, validating the effectiveness of the Hierarchical Recency-Aware Positional Encoding (HRAPE) in adapting to temporal shifts.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Figures/temporal_stability.png}
    \caption{Temporal stability analysis: F1-Score across future time steps.}
    \label{fig:temporal_stability}
\end{figure}

\subsubsection{Hyperparameter Sensitivity}
We analyzed the impact of the hidden dimension size on model performance. Figure~\ref{fig:sensitivity} shows that performance improves with model capacity up to a hidden dimension of 128, after which it plateaus. We selected 64 as the optimal trade-off between accuracy and computational efficiency.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Figures/sensitivity_analysis.png}
    \caption{Impact of hidden dimension size on F1-Score.}
    \label{fig:sensitivity}
\end{figure}

\subsubsection{Runtime Efficiency}
To assess real-time feasibility, we measured the average inference time per batch. RTXGNN achieves an inference latency of less than 50ms, which is comparable to GAT and well within the requirements for real-time fraud detection systems.

\subsection{Evaluation on YelpChi Dataset}

To validate the generalizability of RTXGNN, we evaluated it on the YelpChi dataset. The model achieved a competitive F1-score, demonstrating its effectiveness in detecting fraud in review networks, which differ significantly from financial transaction graphs. This confirms that the proposed HRAPE and SEAL components are not overfitted to a specific domain but capture fundamental properties of dynamic fraud networks.

\subsection{Evaluation on Synthetic Money Laundering Network}

To validate the model's ability to detect structural fraud typologies, we trained and tested RTXGNN on the Synthetic Money Laundering Network. The model achieved a high F1-score, successfully distinguishing the injected "fraud rings" from licit background transactions.

Figure~\ref{fig:synthetic_patterns} visualizes a detected fraud ring. The red nodes represent the illicit actors forming a cyclic transaction pattern, which RTXGNN correctly identified. This confirms that the model learns to recognize complex structural motifs indicative of money laundering.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Figures/synthetic_patterns.png}
    \caption{Visualization of a detected fraud ring (cycle) in the synthetic dataset.}
    \label{fig:synthetic_patterns}
\end{figure}

\subsection{Interpretability and Visualization}

\subsubsection{Explanation Fidelity}
We quantified the quality of our explanations using the Fidelity+ metric, which measures the drop in prediction probability when important features are masked. RTXGNN achieved a positive fidelity score, indicating that the features identified by the SEAL module are indeed the primary drivers of the model's decisions.

\subsubsection{Embedding Visualization}
Figure~\ref{fig:tsne} presents the t-SNE visualization of the learned node embeddings for the test set. The clear separation between licit (blue) and illicit (red) transactions in the 2D latent space demonstrates that RTXGNN learns highly discriminative representations.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Figures/tsne_visualization.png}
    \caption{t-SNE visualization of learned node embeddings, colored by class.}
    \label{fig:tsne}
\end{figure}
